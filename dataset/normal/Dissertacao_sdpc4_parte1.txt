A computação é, sem dúvida, uma área que experimentou um desenvolvimento sem comparação ao longo das últimas quatro décadas. O desenvolvimento do hardware sempre foi sustentado e motivado pelo desenvolvimento da eletrônica. O desenvolvimento do software, entretanto, não acompanha o do hardware na mesma velocidade e uma das maiores barreiras observadas é a dificuldade em se atingir portabilidade e a dificuldade em se migrar de um paradigma de programação para outro, em função do desenvolvimento das arquiteturas de computadores, por exemplo. 
Um dos entraves que se encontra na área da programação paralela corresponde ao forte acoplamento existente entre o software em desenvolvimento e o hardware alvo, isto é, o software é, normalmente, fortemente dependente do hardware e o desenvolvimento visando bom desempenho (um dos objetivos fundamentais da computação paralela) leva à necessidade de se adequar, de modo coerente, o software ao hardware. Outro fator preocupante nesta área ainda é o custo. Na tentativa de solucionar essa situação, apareceram os sistemas distribuídos, que tiveram como objetivo inicial o compartilhamento de recursos. 
Com a necessidade do compartilhamento de recursos, sistemas, antes centralizados, sofreram mudanças em seus modelos arquiteturais e beneficiaram-se da utilização de computadores autônomos conectados por uma rede de comunicação.
O desenvolvimento de software seqüencial, destinado à execução em máquinas tradicionais, que seguem a arquitetura de von Neumann, é uma área bem estabelecida, contando com uma gama diversificada de ferramentas de apoio ao desenvolvimento, depuração e avaliação. Por outro lado, o desenvolvimento de software paralelo, destinado à execução em máquinas baseadas em arquiteturas paralelas, ainda não possui um elenco bem definido e bem estabelecido de ferramentas e metodologias de apoio ao desenvolvimento, depuração e avaliação. 
Algumas metodologias e ferramentas de apoio têm sido propostas e implementadas nos últimos anos, visando cobrir a lacuna existente na área de programação paralela/concorrente. Uma contribuição nessa área corresponde à ferramenta denominada F.A.P.P. (Ferramenta de Apoio à Programação Paralela), proposta em um programa de doutorado desenvolvido dentro do Grupo de Sistemas Distribuídos e Programação Concorrente do ICMC­ USP. O desenvolvimento da F.A.P.P. apresenta uma infra-estrutura de apoio para o desenvolvimento de programas paralelos. Porém, como já enfatizado nesta introdução, em se tratando de software paralelo, o seu desenvolvimento está intimamente ligado à arquitetura alvo. 
A F.A.P.P. é uma ferramenta implementada com base em uma modelagem orientada a objetos, que considera o hardware (a taxonomia de Duncan foi considerada) com seus elementos básicos (processadores, memória, canais de comunicação, etc.) e o software.  Ambos são modelados a partir da teoria dos grafos e segundo o paradigma da orientação a objetos. Assim, software e hardware são reduzidos a um grafo e o modelo global produzido é totalmente orientado a objetos. Isso permite o estabelecimento da ferramenta F.A.P.P., que utiliza a metodologia de desenvolvimento de programas desenvolvida por Foster, que propõe um desenvolvimento análogo ao utilizado em programas seqüenciais, seguindo a técnica de programação por esqueleto proposta por Zima e Chapman. 
A F.A.P.P. é baseada em uma técnica de modelagem, que permite a incorporação de novas tecnologias, tanto em nível de hardware como de software. Dessa forma, a primeira especialização da ferramenta, foi desenvolvida (por razões históricas) para programação baseada em Occam2 e transputers. A ferramenta está operacional para esse ambiente de programação e o objetivo desta dissertação de mestrado é o desenvolvimento da modelagem necessária e da especialização da F.A.P.P. para ambientes paralelos virtuais. 
A escolha de ambientes paralelos virtuais, que correspondem atualmente às plataformas de passagens de mensagens (ou plataformas de portabilidade) executando sobre sistemas computacionais distribuídos, está intimamente ligada à vasta utilização e difusão desses ambientes, nas mais diferentes áreas do conhecimento. 
A computação paralela em ambientes paralelos virtuais é bastante versátil, permitindo que a busca por alto desempenho possa ser exercitada a partir de plataformas computacionais distribuídas. Isso traz benefícios diversificados, incluindo uma possível queda na relação custo/benefício da computação paralela, uma vez que ambientes distribuídos (por exemplo, redes de estações de trabalho ou computadores pessoais) podem ser utilizados para esse fim. 
Os dois exemplos atuais mais discutidos na literatura e utilizados de fato são o PVM e o MPI. O PVM é considerado um padrão de fato, dado a sua vasta utilização e popularidade alcançadas não apenas no meio acadêmico, mas também em diversas aplicações na indústria e outros setores. O MPI, por sua vez, foi proposto para ser um padrão internacional de biblioteca de passagem de mensagens e vem, aos poucos, conquistando adeptos e demonstrando seu potencial. Ambos, PVM e MPI são alvos de estudos e considerações no desenvolvimento deste projeto. 
O objetivo desta dissertação é a extensão da Ferramenta de Apoio à Programação Paralela para ambientes paralelos virtuais tais como o PVM (Paralell Virtual Machine) e o MPI (Message Passing Interface). 
Devido a sua grande utilização e características como simplicidade, robustez e eficiência, o ambiente de passagem de mensagens PVM, desenvolvido por Geist et al, é utilizado como base para teste e validação da Ferramenta em questão. 
Embora o termo desempenho esteja diretamente relacionado com a computação paralela, o objetivo principal deste trabalho é permitir a utilização da computação paralela especificamente em ambientes paralelos de uma maneira mais fácil e direta, possibilitando assim a utilização desses ambientes até por usuários sem conhecimento dos mesmos.