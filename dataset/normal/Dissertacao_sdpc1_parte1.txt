Os últimos anos têm apresentado um grande aumento na aceitação e adoção do processamento paralelo, tanto para computação científica de alto desempenho como para aplicações de propósito geral. Essa aceitação tem sido favorecida principalmente pelo desenvolvimento dos ambientes com processamento maciçamente paralelo (MPP ­ Massively Parallel Processing) e da computação distribuída. 
A computação paralela e a computação distribuída surgiram por motivos diferentes. A necessidade de se compartilhar recursos motivou o uso de sistemas distribuídos, enquanto a busca por maior desempenho no processo computacional motivou a utilização do processamento paralelo. Atualmente, as duas áreas têm convergido, de maneira que a combinação entre os dois enfoques computacionais oferece benefícios para ambos os lados. A utilização de sistemas distribuídos para computação paralela oferece flexibilidade e uma maneira eficiente de se explorar hardware interligado já disponível. 
Um ponto comum entre sistemas distribuídos e ambientes MPPs é a noção de passagem de mensagem, que permite a comunicação entre processos paralelos. Um ambiente de passagem de mensagem consiste basicamente de uma biblioteca de comunicação que, atuando como uma extensão das linguagens seqüenciais (como C e Fortran), permite a elaboração de aplicações paralelas. Para a maioria desses sistemas, ambientes para passagem de mensagem portáteis têm sido desenvolvidos, dos quais dois representantes merecem destaque no cenário computacional atual: o PVM (Parallel Virtual Machine) e o MPI (Message Passing Interface). 
O PVM destaca­se por ser considerado por alguns autores um padrão de fato para plataformas de portabilidade, enquanto o MPI é uma tentativa de padronização de direito, levada a cabo por diversas organizações mundiais. 
O PVM tem mostrado as vantagens da programação paralela portátil. Entre os principais motivos do sucesso do PVM destacam­se: seu domínio público, sua simplicidade, a portabilidade de suas aplicações e sua emulação de uma máquina paralela virtual. O PVM não foi projetado para sistemas paralelos fortemente acoplados, sendo melhor utilizado em computação distribuída. 
O objetivo principal do MPI é garantir eficiência em qualquer plataforma paralela (arquiteturas paralelas ou sistemas distribuídos) e segundo Geist, o MPI implementado em máquinas paralelas apresenta melhor desempenho do que em sistemas distribuídos. Algumas implementações do MPI já estão disponíveis em domínio público, para diversas plataformas. 
Assim, o objetivo deste trabalho é verificar as afirmações discutidas nos parágrafos anteriores, ou seja, segundo Geist o MPI é mais adequado para arquiteturas paralelas, enquanto o PVM se adapta melhor em sistemas distribuídos. Para tanto, visa­se analisar e comparar o desempenho do PVM e do MPI, implementados tanto em sistemas distribuídos como em máquinas paralelas. 
Esta análise é realizada através do desenvolvimento de vários algoritmos paralelos de ordenação, utilizando tanto PVM quanto MPI e da execução desses algoritmos em um sistema distribuído (baseado em computadores do tipo PC) e em uma máquina paralela SP2 (Scalable POWERparallel System 2) da IBM. 
A análise a ser efetuada considera diferentes algoritmos paralelos de ordenação (em linguagem C), com diferentes granulações (média e grossa), modelos de programação (SPMD ou MPMD) e comunicações (considerando número e tamanho das mensagens). 
Através dos dados obtidos para se analisar os ambientes e as plataformas, pode­se adicionalmente comparar diversos algoritmos de ordenação. 
Os testes foram realizados em quatro implementações. No sistema distribuído utilizou­se as plataformas de portabilidade PVM versão 3.3.10 e MPICH versão 1.0.12 (uma implementação da especificação MPI). Enquanto que na máquina paralela SP2 adotou­se duas implementações proprietárias da IBM, sendo IBM PVMe e IBM MPI. 
Foram realizados também testes comparativos com os algoritmos seqüenciais correspondentes, a fim de se verificar os speedups alcançados com a execução dos algoritmos paralelos de ordenação utilizando cada plataforma. Além disso, foi incluído um estudo das comunicações ponto­a­ponto e coletivas do PVM e do MPI, que foram utilizados para uma melhor avaliação dos resultados obtidos. 
